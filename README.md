# Flash Attention Windows Wheels

Pre-built Windows wheels for [Flash-Attention 2](https://github.com/Dao-AILab/flash-attention) - The state-of-the-art efficient attention implementation for NVIDIA GPUs.

## cp310
```
pip install flash_attn-2.7.0.post2-cp310-cp310-win_amd64.whl
```
